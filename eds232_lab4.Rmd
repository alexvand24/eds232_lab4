---
title: "Lab 4 - Deep Learning"
author: "Alex Vand"
date: "`r Sys.Date()`"
output: 
  html_document:
    number_sections: true
    code_folding: hide
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


# R

## Install python for R


```{r}
# load libraries
librarian::shelf(
  devtools,
  keras,
  reticulate,
  tensorflow)

# show library versions and paths
session_info() 

# install Python into user space
(reticulate::miniconda_path()) # show the Python path
if (!file.exists(reticulate::miniconda_path()))
  reticulate::install_miniconda()

# install keras with tensorflow
if (!keras::is_keras_available())
  keras::install_keras()
```


## Loading the MNIST dataset in Keras

```{r}
library(keras)
mnist <- dataset_mnist()
```


```{r}
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images  <- mnist$test$x
test_labels  <- mnist$test$y
```


```{r}
str(train_images)
```


```{r}
str(train_labels)
```


```{r}
str(test_images)
```


```{r}
str(test_labels)
```


```{r}
librarian::shelf(glue)

dim(train_images)
```

```{r}
dim(train_labels)
```

```{r}
par(mfrow=c(2,2))
sapply(
  1:4, function(i){ # i = 5
    plot(
      as.raster(train_images[i,,]/255),
      main = glue("image_{i}: label = {train_labels[i]}")) })
```




## The network architecture


```{r}
network <- keras_model_sequential() %>% 
  layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>% 
  layer_dense(units = 10, activation = "softmax")
```



## The compilation step

```{r}
network %>% compile(
  optimizer = "rmsprop",
  loss      = "categorical_crossentropy",
  metrics   = c("accuracy"))
```



## Preparing the image data

```{r}
train_images <- array_reshape(train_images, c(60000, 28 * 28))
train_images <- train_images / 255
test_images  <- array_reshape(test_images, c(10000, 28 * 28))
test_images  <- test_images / 255
```


## Preparing the labels

```{r}
train_labels <- to_categorical(train_labels)
test_labels  <- to_categorical(test_labels)
```


```{r}
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
```


```{r}
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
```




# iNaturalist

```{r}
librarian::shelf(
  digest, dplyr, DT, glue, purrr, readr, stringr, tidyr)

# path to folder containing species directories of images
dir_src  <- "/courses/EDS232/inaturalist-2021/train_mini"
dir_dest <- "~/inat"
dir.create(dir_dest, showWarnings = F)

# get list of directories, one per species (n = 10,000 species)
dirs_spp <- list.dirs(dir_src, recursive = F, full.names = T)
n_spp <- length(dirs_spp)

# set seed (for reproducible results) 
# just before sampling (otherwise get different results)
# based on your username (unique amongst class)
Sys.info()[["user"]] %>% 
  digest::digest2int() %>% 
  set.seed()
i10 <- sample(1:n_spp, 10)

# show the 10 indices sampled of the 10,000 possible 
i10
```




```{r}
# show the 10 species directory names
basename(dirs_spp)[i10]
```


```{r}
# show the first 2 species directory names
i2 <- i10[1:2]
basename(dirs_spp)[i2]
```


```{r}
# setup data frame with source (src) and destination (dest) paths to images
d <- tibble(
  set     = c(rep("spp2", 2), rep("spp10", 10)),
  dir_sp  = c(dirs_spp[i2], dirs_spp[i10]),
  tbl_img = map(dir_sp, function(dir_sp){
    tibble(
      src_img = list.files(dir_sp, full.names = T),
      subset  = c(rep("train", 30), rep("validation", 10), rep("test", 10))) })) %>% 
  unnest(tbl_img) %>% 
  mutate(
    sp       = basename(dir_sp),
    img      = basename(src_img),
    dest_img = glue("{dir_dest}/{set}/{subset}/{sp}/{img}"))

# show source and destination for first 10 rows of tibble
d %>% 
  select(src_img, dest_img)
```




```{r}
# iterate over rows, creating directory if needed and copying files 
d %>% 
  pwalk(function(src_img, dest_img, ...){
    dir.create(dirname(dest_img), recursive = T, showWarnings = F)
    file.copy(src_img, dest_img) })

# uncomment to show the entire tree of your destination directory
 system(glue("tree {dir_dest}"))
```



## 2 Species data

### Data preprocessing

```{r}
train_dir_spp2 <- paste0(dir_dest,"/spp2/train")
validation_dir_spp2 <- paste0(dir_dest,"/spp2/validation")
test_dir_spp2 <- paste0(dir_dest,"/spp2/test")
```


```{r}
# All images will be rescaled by 1/255
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)
test_datagen <- image_data_generator(rescale = 1/255)

train_generator_spp2 <- flow_images_from_directory(
  # This is the target directory
  train_dir_spp2,
  # This is the data generator
  train_datagen,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 10,
  # Since we use binary_crossentropy loss, we need binary labels
  class_mode = "binary")

validation_generator_spp2 <- flow_images_from_directory(
  validation_dir_spp2,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 10,
  class_mode = "binary")

test_generator_spp2 <- flow_images_from_directory(
  test_dir_spp2,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 10,
  class_mode = "binary")
```


### Neural network

```{r}
model_spp2_nn <- keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(150, 150, 3)) %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units =  1, activation = "sigmoid")
```



```{r}
model_spp2_nn %>% compile(
  optimizer = "rmsprop",
  loss      = "binary_crossentropy",
  metrics   = c("accuracy"))
```


# ??? code breaks here
but works for cnn

```{r}
history_spp2_nn <- model_spp2_nn %>% fit(
  train_generator_spp2,
  epochs = 20,
  steps_per_epoch = 5,
  validation_data = validation_generator_spp2)
```


```{r}
plot(history_spp2_nn)
```



```{r}
eval_spp2_nn <- evaluate(model_spp2_nn, test_generator_spp2)
eval_spp2_nn
```



### Convolutional neural network


```{r}
model_spp2_cnn <- keras_model_sequential() %>% 
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
                input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_flatten() %>% 
  layer_dense(units = 512, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")
```


why not save as new object? why just pipe into compile?

```{r}
model_spp2_cnn %>% compile(
  optimizer = "rmsprop",
  loss      = "binary_crossentropy",
  metrics   = c("accuracy"))
```


```{r}
history_spp2_cnn <- model_spp2_cnn %>% fit(
  train_generator_spp2,
  epochs = 20,
  steps_per_epoch = 5,
  validation_data = validation_generator_spp2)
```


```{r}
plot(history_spp2_cnn)
```


```{r}
eval_spp2_cnn <- evaluate(model_spp2_cnn, test_generator_spp2)
eval_spp2_cnn
```

### Compare




## 10 Species data

### Data preprocessing

```{r}
train_dir_spp10 <- paste0(dir_dest,"/spp10/train")
validation_dir_spp10 <- paste0(dir_dest,"/spp10/validation")
test_dir_spp10 <- paste0(dir_dest,"/spp10/test")
```


```{r}
# All images will be rescaled by 1/255
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)
test_datagen <- image_data_generator(rescale = 1/255)

train_generator_spp10 <- flow_images_from_directory(
  # This is the target directory
  train_dir_spp10,
  # This is the data generator
  train_datagen,
  # All images will be resized to 150x150
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "categorical")

validation_generator_spp10 <- flow_images_from_directory(
  validation_dir_spp10,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "categorical")

test_generator_spp10 <- flow_images_from_directory(
  test_dir_spp10,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "categorical")
```

### Neural network


```{r}
model_spp10_nn <- keras_model_sequential() %>% 
  layer_dense(units = 16, activation = "relu", input_shape = c(150, 150, 3)) %>% 
  layer_dense(units = 16, activation = "relu") %>% 
  layer_dense(units = 10, activation = "softmax") # change to 10 units because we have 10 classes
```



```{r}
model_spp10_nn %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)
```


# ??? code breaks here
but works for cnn


do I need to flatten?


  batch_size = 5?
  steps_per_epoch = 5?

```{r}
history_spp10_nn <- model_spp10_nn %>% fit(
  train_generator_spp10,
  epochs = 20,
  steps_per_epoch = 5,
  validation_data = validation_generator_spp10)
```


```{r}
plot(history_spp10_nn)
```



```{r}
eval_spp10_nn <- evaluate(model_spp10_nn, test_generator_spp10)
eval_spp10_nn
```


### Convolutional neural network


```{r}
model_spp10_cnn <- keras_model_sequential() %>% 
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
                input_shape = c(150, 150, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_flatten() %>% 
  layer_dense(units = 512, activation = "relu") %>% 
  layer_dense(units = 10, activation = "softmax")
```


why not save as new object? why just pipe into compile?

```{r}
model_spp10_cnn %>% compile(
  optimizer = "rmsprop",
  loss      = "categorical_crossentropy",
  metrics   = c("accuracy"))
```


```{r}
history_spp10_cnn <- model_spp10_cnn %>% fit(
  train_generator_spp10,
  epochs = 20,
  batch_size =5,
  validation_data = validation_generator_spp10)
```


```{r}
plot(history_spp10_cnn)
```


```{r}
eval_spp10_cnn <- evaluate(model_spp10_cnn, test_generator_spp10)
eval_spp10_cnn
```



### Compare




